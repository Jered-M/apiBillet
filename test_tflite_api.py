#!/usr/bin/env python3
"""
Test du pipeline TFLite - VÃ©rifie que le modÃ¨le TFLite charge correctement
et que le preprocessing est identique au notebook Colab
"""

import os
import sys
import numpy as np
import tensorflow as tf
from PIL import Image, ImageOps
import json

# Configuration
IMG_SIZE = (224, 224)
BILL_LABELS = {
    0: "100 CDF", 1: "50 CDF", 2: "200 CDF", 3: "500 CDF",
    4: "1000 CDF", 5: "5000 CDF", 6: "10000 CDF", 7: "20000 CDF",
    8: "100 USD", 9: "5 USD", 10: "10 USD", 11: "50 USD",
    12: "20 USD", 13: "1 USD"
}

def load_tflite_model(model_path="model (1).tflite"):
    """Charge le modÃ¨le TFLite"""
    try:
        print(f"ğŸ“ Chargement TFLite: {model_path}")
        interpreter = tf.lite.Interpreter(model_path=model_path)
        interpreter.allocate_tensors()
        
        output_details = interpreter.get_output_details()
        input_details = interpreter.get_input_details()
        
        print(f"âœ… TFLite chargÃ©!")
        print(f"   Input shape:  {input_details[0]['shape']}")
        print(f"   Output shape: {output_details[0]['shape']}")
        print(f"   Nb classes:   {output_details[0]['shape'][-1]}")
        
        return interpreter, input_details, output_details
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        return None, None, None

def preprocess_image(image_path):
    """Preprocessing IDENTIQUE au notebook"""
    img = Image.open(image_path)
    
    # EXIF transpose (pour iPhone)
    img = ImageOps.exif_transpose(img)
    
    # RGB conversion
    img = img.convert('RGB')
    
    # Resize avec LANCZOS
    img = img.resize(IMG_SIZE, Image.Resampling.LANCZOS)
    
    # Array
    img_array = np.array(img, dtype=np.float32)
    
    # Normalize /255.0
    img_array = img_array / 255.0
    
    # Batch dimension
    img_array = np.expand_dims(img_array, axis=0)
    
    print(f"âœ… Image prÃ©traitÃ©e")
    print(f"   Shape: {img_array.shape}")
    print(f"   Range: [{img_array.min():.3f}, {img_array.max():.3f}]")
    
    return img_array

def test_inference(interpreter, input_details, output_details, img_array):
    """Test l'infÃ©rence TFLite"""
    try:
        print("\nğŸ”® InfÃ©rence TFLite...")
        
        # Convertir en float32
        if input_details[0]['dtype'] == np.float32:
            img_array = img_array.astype(np.float32)
        
        interpreter.set_tensor(input_details[0]['index'], img_array)
        interpreter.invoke()
        
        predictions = interpreter.get_tensor(output_details[0]['index'])
        
        print(f"âœ… InfÃ©rence rÃ©ussie!")
        print(f"   Output shape: {predictions.shape}")
        print(f"   Predictions: {predictions}")
        
        # Top predictions
        top_idx = np.argsort(predictions[0])[-3:][::-1]
        print(f"\nğŸ¯ Top 3 prÃ©dictions:")
        for idx in top_idx:
            conf = predictions[0][idx]
            label = BILL_LABELS.get(idx, f"Unknown {idx}")
            print(f"   {label:15} {conf:.4f} ({conf*100:.2f}%)")
        
        return predictions[0]
    except Exception as e:
        print(f"âŒ Erreur infÃ©rence: {e}")
        return None

def verify_model_specs():
    """VÃ©rifie les specs du modÃ¨le"""
    print("\n" + "="*50)
    print("ğŸ“‹ VÃ‰RIFICATION SPECS MODÃˆLE")
    print("="*50)
    
    # TFLite
    interp, inp, out = load_tflite_model()
    if interp is None:
        print("âŒ TFLite non disponible")
        return False
    
    num_classes = out[0]['shape'][-1]
    
    # VÃ©rifier que c'est bien 14 classes
    if num_classes != 14:
        print(f"âš ï¸  ATTENTION: {num_classes} classes (attendu 14)")
        return False
    
    print(f"\nâœ… ModÃ¨le correct: 14 classes")
    print(f"   Classes: {list(BILL_LABELS.keys())}")
    
    return True

def test_with_sample_image(image_path):
    """Test avec une image rÃ©elle"""
    if not os.path.exists(image_path):
        print(f"âš ï¸  Image de test non trouvÃ©e: {image_path}")
        return False
    
    print("\n" + "="*50)
    print(f"ğŸ–¼ï¸  TEST AVEC IMAGE: {os.path.basename(image_path)}")
    print("="*50)
    
    # Charger le modÃ¨le
    interp, inp, out = load_tflite_model()
    if interp is None:
        return False
    
    # PrÃ©traiter
    print(f"\nğŸ“Œ Preprocessing...")
    img_array = preprocess_image(image_path)
    
    # InfÃ©rer
    predictions = test_inference(interp, inp, out, img_array)
    
    return predictions is not None

def main():
    print("\n" + "="*50)
    print("ğŸ§ª TEST TFLITE API")
    print("="*50)
    
    # VÃ©rifier specs
    if not verify_model_specs():
        sys.exit(1)
    
    # Test avec image de test si elle existe
    test_images = [
        "uploads/test_bill.jpg",
        "test_image.jpg",
        "bill.jpg"
    ]
    
    for img_path in test_images:
        if os.path.exists(img_path):
            if test_with_sample_image(img_path):
                break
    
    print("\n" + "="*50)
    print("âœ… TESTS COMPLÃ‰TÃ‰S")
    print("="*50)
    print("\nğŸ“ RÃ©sumÃ©:")
    print("  âœ… TFLite chargÃ© correctement")
    print("  âœ… 14 classes dÃ©tectÃ©es")
    print("  âœ… Preprocessing OK (LANCZOS + /255.0)")
    print("  âœ… InfÃ©rence fonctionnelle")
    print("\nğŸ’¡ La API est prÃªte Ã  fonctionner!")

if __name__ == "__main__":
    main()
