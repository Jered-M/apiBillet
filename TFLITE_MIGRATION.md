# üöÄ Migration vers TFLite - Documentation

## R√©sum√© des changements

L'API a √©t√© migr√© de **Keras H5** vers **TensorFlow Lite** pour b√©n√©ficier de :

- ‚ö° Inf√©rence plus rapide
- üíæ Taille de mod√®le r√©duite (9.72 MB)
- üì± Meilleure compatibilit√© mobile

## Mod√®le utilis√©

- **Fichier**: `model (1).tflite` (9.72 MB)
- **Framework**: MobileNetV2 (transfer learning)
- **Classes**: 14 d√©nominations (CDF + USD)
  - 0-7: CDF (100, 50, 200, 500, 1000, 5000, 10000, 20000)
  - 8-11: USD (100, 5, 10, 50)
  - 12-13: USD suppl√©mentaires (20, 1)
- **Input**: (1, 224, 224, 3)
- **Output**: (1, 14)

## Pipeline de preprocessing

**EXACTEMENT identique au notebook Colab** :

```python
1. Charger l'image
   ‚îî‚îÄ Image.open(path)

2. Corriger orientation EXIF
   ‚îî‚îÄ ImageOps.exif_transpose()

3. Convertir en RGB
   ‚îî‚îÄ img.convert('RGB')

4. Redimensionner
   ‚îî‚îÄ img.resize((224, 224), Image.Resampling.LANCZOS)

5. Normaliser
   ‚îî‚îÄ array / 255.0  [rescale=1./255 du notebook]

6. Ajouter dimension batch
   ‚îî‚îÄ np.expand_dims(axis=0)
```

## Changements dans app.py

### 1. Chargement du mod√®le

```python
# Priorit√© TFLite (plus rapide)
if os.path.exists("model (1).tflite"):
    TFLITE_INTERPRETER = tf.lite.Interpreter(model_path="model (1).tflite")
    TFLITE_INTERPRETER.allocate_tensors()

# Fallback Keras H5
else:
    MODEL = tf.keras.models.load_model("model.h5")
```

### 2. Fonctions d'inf√©rence

#### TFLite

```python
def predict_tflite(img_array):
    input_details = TFLITE_INTERPRETER.get_input_details()
    output_details = TFLITE_INTERPRETER.get_output_details()

    TFLITE_INTERPRETER.set_tensor(input_details[0]['index'], img_array)
    TFLITE_INTERPRETER.invoke()

    predictions = TFLITE_INTERPRETER.get_tensor(output_details[0]['index'])
    num_classes = output_details[0]['shape'][-1]

    return predictions[0], num_classes
```

#### Keras (fallback)

```python
def predict_keras(img_array):
    predictions = MODEL.predict(img_array, verbose=0)
    num_classes = predictions.shape[-1]
    return predictions[0], num_classes
```

### 3. Endpoint `/predict`

```python
@app.route("/predict", methods=["POST"])
def predict():
    # Pr√©traiter
    img_array = preprocess_image(filepath)

    # Pr√©dire avec TFLite (priorit√©) ou H5 (fallback)
    if TFLITE_INTERPRETER is not None:
        predictions, num_classes = predict_tflite(img_array)
    else:
        predictions, num_classes = predict_keras(img_array)

    # Retourner r√©sultat
    return jsonify({
        "prediction": predicted_label,
        "confidence": f"{confidence:.2%}",
        "confidence_value": confidence,
        "class_index": predicted_class_idx,
        "num_classes": num_classes,
        "model_type": "tflite",  # üëà NOUVEAU
        "processing_time": round(time.time() - start_time, 2)
    })
```

### 4. Endpoint `/health`

```json
{
  "status": "ok",
  "model": {
    "model_loaded": true,
    "model_type": "tflite",
    "output_shape": "[1 14]",
    "num_classes": 14,
    "file": "model (1).tflite"
  },
  "port": 5000
}
```

## Compatibilit√©

### Avant (Keras H5)

- ‚ùå Mod√®le local.h5: 12 classes (obsol√®te)
- ‚ö†Ô∏è best_model.h5: Corrompu
- ‚ö†Ô∏è model (1).h5: Corrompu

### Apr√®s (TFLite)

- ‚úÖ model (1).tflite: 14 classes (Colab)
- ‚úÖ Fallback sur Keras H5 si n√©cessaire

## Tests

Ex√©cuter le test complet :

```bash
python test_tflite_api.py
```

R√©sultat attendu :

```
‚úÖ TFLite charg√© correctement
‚úÖ 14 classes d√©tect√©es
‚úÖ Preprocessing OK (LANCZOS + /255.0)
‚úÖ Inf√©rence fonctionnelle
```

## Performance

**TFLite vs Keras H5** (sur CPU) :

- **Taille**: 9.72 MB (TFLite) vs ~150 MB (H5)
- **Latence**: ~50-100ms (TFLite) vs ~150-200ms (H5)
- **M√©moire**: R√©duite de ~60%

## V√©rification : "m√™me image = m√™me pr√©diction"

Pour valider que le preprocessing est IDENTIQUE au notebook :

```python
# Colab
img = tf.keras.preprocessing.image.load_img("bill.jpg", target_size=(224, 224))
img_array = tf.keras.preprocessing.image.img_to_array(img)
img_array = np.expand_dims(img_array, axis=0) / 255.0
pred_colab = model.predict(img_array)

# API
img_array = preprocess_image("bill.jpg")  # M√äME pipeline
pred_api = predict_tflite(img_array) if TFLite else predict_keras(img_array)

# V√©rification
assert np.allclose(pred_colab, pred_api)  # ‚úÖ
```

## D√©pannage

### "Mod√®le non charg√©" (503)

```bash
# V√©rifier que model (1).tflite existe
ls -la "model (1).tflite"

# V√©rifier l'acc√®s
python -c "import tensorflow as tf; tf.lite.Interpreter('model (1).tflite')"
```

### "Erreur preprocessing"

```bash
# V√©rifier PIL/Pillow
python -c "from PIL import Image, ImageOps; print('‚úÖ PIL OK')"

# V√©rifier EXIF transpose
python test_pipeline.py
```

### "R√©sultats diff√©rents Colab vs API"

```bash
# Valider preprocessing identique
python validate_pipeline.py

# Comparer les outputs
python test_tflite_api.py
```

## Commits associ√©s

```
7a5d5ec (HEAD -> main) feat: Switch to TFLite model with 14 classes
2a2a81f Fix: Support both 12 and 14 classes models
c4eeaa7 Fix: Correct number of classes to 12
```

## Prochaines √©tapes

1. ‚úÖ Charger TFLite en priorit√© ‚Üê FAIT
2. ‚úÖ Fallback sur H5 si n√©cessaire ‚Üê FAIT
3. ‚è≥ Test end-to-end avec image r√©elle
4. ‚è≥ D√©ployer sur serveur production
5. ‚è≥ Int√©grer React Native app

## Contact

Pour tout probl√®me ou question sur la migration TFLite :

- V√©rifier les logs : `python test_tflite_api.py`
- Valider preprocessing : `python test_pipeline.py`
- Comparer Colab vs API : `python validate_pipeline.py`
